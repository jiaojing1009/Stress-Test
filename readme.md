# 报告文档：
---
![运行模型](https://github.com/jiaojing1009/Stress-Test/blob/master/运行模型.png)
由于GIL(全局解释器锁)的存在，任一时间内只能有一个线程使用解释器，跟单CPU跑多程序类似，并不能做到真正的并发，当线程执行一个计算密集型的任务时，其他线程只能等待。所以我们这里使用ProcessPoolExecutor进程池来解决并发问题
---
## 代码：
- **A端**中做Json数据处理，超时处理，异常处理，通过线程池，Request请求向B接口发起请求


- **B端**做Json数据异常处理，
Queue值设置为1000，较大的长度可以用作缓冲，
使用进程池，来接收A端发起的请求，并加入到接收队列中
判断接收队列的长度，使用线程池+队列的模式，异步的进行AI操作
根据真实业务情况，判断每次执行AI操作的间隔，当请求数量不足batch_size或长时间未处理AI请求时，进行AI处理

---
## 结论：
以下运行结果在本地CentOS虚拟机上执行，
本机配置：CPU 四核八线程 内存DDR4 8G
**为减小误差，每一种情况运行三次取平均值**

![运行结果](https://github.com/jiaojing1009/Stress-Test/blob/master/运行结果ts_diff和QPS变化.jpg)

当ThreadPoolExecutor Max值提高时，ts_diff有明显上升，QPS先小幅上升后基本保持不变
当batch_size提高时，ts_diff时间明显下降

### 原因
**ThreadPoolExecutor**内部维护一个**无界队列**，当提交的任务数超过了MaxPoolSize，会将当前的线程提交到一个**block queue**中，造成阻塞，如果线程池MaxSize过小，导致每次存活的请求数过少，接收队列Queue的长度也就过小，从而影响ts_diff.线程池的大小也决定池内部是否频繁更新线程状态，当线程池MaxSize提高后，更新状态不那么频繁，QPS也就上升了
---
## 对比
**QPS**的瓶颈在B端如何处理：

因为有**GIL**的存在，要跑满**CPU**只能用**多进程**来实现B端
**这里B端分为三种多任务实现模型**

- **多进程模式**

    启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。

    采用**A端**多线程，**B端**多进程的方法，增大CPU使用率，多核心执行AI操作速度提升很大，但本次并未真正的实现多进程**后期有待改进**

- **多线程模式**
    启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。

    采用**A端**多线程。**B端**多线程的办法，依旧是**一个CPU核心**在运行跑不满CPU占用率，串行跑AI操作，虽然是**异步**但速度并没有提升很大

- **多进程+多线程模式**

    启动多个进程，每个进程再启动多个线程，这样同时执行的任务就更多了，当然这种模型更复杂，实际很少采用。

### 进程VS线程
多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。

多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。

多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。

